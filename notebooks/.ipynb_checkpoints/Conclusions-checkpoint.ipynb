{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt # plots\n",
    "import seaborn as sns # plots\n",
    "from scipy import stats as sts # normality test JB\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge, RidgeCV # Ridge\n",
    "from sklearn.linear_model import Lasso, LassoCV # Lasso\n",
    "from sklearn.linear_model import LogisticRegression # Log Regression\n",
    "from sklearn.metrics import r2_score # R^2\n",
    "from sklearn.model_selection import train_test_split # split data\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error # MSE\n",
    "from sklearn.preprocessing import StandardScaler # estandarization\n",
    "from sklearn import preprocessing # estandarization\n",
    "from sklearn.ensemble import IsolationForest # outliers\n",
    "from math import sqrt # sqrt\n",
    "import itertools # aplanar arrays\n",
    "import math\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve # ROC Curve\n",
    "from sklearn.datasets import make_classification\n",
    "import random\n",
    "random.seed(12345)\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we started our project, we found a dataset where there are a lot of variables, among which there are future variables that the bank would not have at the time of studying the client. We have treated the lost values and we have made a lasso with the most important variables that we have decided after the data cleaning. Finally we have been left with 23 variables (where 1 of them was the target). We have made different models, with the purpose of observing the percentage of accuracy, that is, to identify or not that client who is going to pay or not the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study the accuracy percentage, we have made the following models:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Support Vector Machine\n",
    "3. Random Forest\n",
    "4. XGBoost\n",
    "\n",
    "After the results obtained and comparing the models, we conclude that the worst model is the SVM, although the accuracy of calculating the 0 (those who are going to pay back the loan) is 78%, the accuracy of the 1 (those who are not going to pay back the loan) is 31%. Therefore, we believe that this model could produce many errors in predicting the 1, so we would discard this model. By studying the Logistic model, we have obtained 95% accuracy for the 0 and 74% for the 1, so we can see how the accuracy of detecting a customer who does not pay has increased considerably. However, the Random Forest model has a higher accuracy for the 1, but lower for 0: 94% of success for the 0 and 79% for the 1, which would cause less error when classifying future customers. Finally, we consider that the xgboost model is our best option, since it has 93% accuracy for 0 amd 81% accuracy for 1, surpassing the logistic regression model. Therefore, the order of preference of our models would be (from highest to lowest): Xgboost > Random Forest > Logistic Regression  > SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.interactivechaos.com/manual/tutorial-de-machine-learning/la-funcion-getdummies\n",
    "    \n",
    "https://empresas.blogthinkbig.com/precauciones-la-hora-de-normalizar/\n",
    "\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
    "\n",
    "https://medium.com/data-design/getting-the-most-of-xgboost-and-lightgbm-speed-compiler-cpu-pinning-374c38d82b86\n",
    "\n",
    "https://www.cienciadedatos.net/documentos/27_regresion_logistica_simple_y_multiple\n",
    "\n",
    "https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lending)",
   "language": "python",
   "name": "lending"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
